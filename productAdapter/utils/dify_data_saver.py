#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Difyæ•°æ®ä¿å­˜å·¥å…·æ¨¡å—
æä¾›ä¿å­˜Difyè¿”å›æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶çš„åŠŸèƒ½
"""

import os
import json
import time
import logging
import threading
import queue
from datetime import datetime
from typing import List, Any, Dict, Optional, Tuple

logger = logging.getLogger(__name__)

def save_dify_response_data(
    response_id: str,
    query: Any,
    all_content: List[str],
    chunk_count: int,
    processing_time: float,
    project_root: str,
    filename_prefix: str = "dify"
) -> Optional[str]:
    """
    ä¿å­˜Difyè¿”å›çš„æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶
    
    Args:
        response_id: å“åº”ID
        query: æŸ¥è¯¢å†…å®¹
        all_content: æ‰€æœ‰æ•°æ®å—å†…å®¹åˆ—è¡¨
        chunk_count: æ•°æ®å—æ•°é‡
        processing_time: å¤„ç†æ—¶é—´
        project_root: é¡¹ç›®æ ¹ç›®å½•
        filename_prefix: æ–‡ä»¶åå‰ç¼€ï¼Œé»˜è®¤ä¸º"dify"
        
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¿å­˜å¤±è´¥åˆ™è¿”å›None
    """
    try:
        # ç”Ÿæˆæ–‡ä»¶åï¼šdify_å¹´æœˆæ—¥æ—¶åˆ†ç§’
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename_prefix}_{timestamp}.txt"
        
        # ç¡®ä¿logsç›®å½•å­˜åœ¨
        logs_dir = os.path.join(project_root, "logs")
        os.makedirs(logs_dir, exist_ok=True)
        
        # æ–‡ä»¶å®Œæ•´è·¯å¾„
        file_path = os.path.join(logs_dir, filename)
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            "response_id": response_id,
            "query": query,
            "timestamp": timestamp,
            "chunk_count": chunk_count,
            "processing_time": processing_time,
            "content": all_content
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# Difyå“åº”æ•°æ® - {timestamp}\n")
                f.write(f"# å“åº”ID: {response_id}\n")
                f.write(f"# æŸ¥è¯¢å†…å®¹: {json.dumps(query, ensure_ascii=False, indent=2)}\n")
                f.write(f"# æ•°æ®å—æ•°é‡: {chunk_count}\n")
                f.write(f"# å¤„ç†æ—¶é—´: {save_data['processing_time']:.2f}ç§’\n")
                f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 50 + "\n\n")
                
                # å†™å…¥æ‰€æœ‰æ•°æ®å—å†…å®¹
                for i, content in enumerate(all_content, 1):
                    f.write(f"## æ•°æ®å— {i}\n")
                    f.write(content)
                    f.write("\n\n")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸåˆ›å»º
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                logger.info(f"ğŸ’¾ Difyå“åº”æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {file_path} (å¤§å°: {file_size} å­—èŠ‚)")
                print(f"ğŸ’¾ Difyå“åº”æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {file_path}")
                print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {os.path.abspath(file_path)}")
                print(f"ğŸ“Š æ•°æ®å—æ•°é‡: {chunk_count}")
                print(f"â±ï¸ å¤„ç†æ—¶é—´: {save_data['processing_time']:.2f}ç§’")
                print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                return file_path
            else:
                logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                print(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
                
        except IOError as io_error:
            error_msg = f"å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {str(io_error)}"
            logger.error(f"âŒ {error_msg}")
            print(f"âŒ {error_msg}")
            return None
        except Exception as write_error:
            error_msg = f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(write_error)}"
            logger.error(f"âŒ {error_msg}")
            print(f"âŒ {error_msg}")
            return None
            
    except Exception as save_error:
        error_msg = f"ä¿å­˜Difyå“åº”æ•°æ®åˆ°æ–‡ä»¶æ—¶å‡ºé”™: {str(save_error)}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return None

def save_dify_response_data_with_metadata(
    response_id: str,
    query: Any,
    all_content: List[str],
    chunk_count: int,
    processing_time: float,
    project_root: str,
    additional_metadata: Optional[Dict[str, Any]] = None,
    filename_prefix: str = "dify"
) -> Optional[str]:
    """
    ä¿å­˜Difyè¿”å›çš„æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆå¸¦é¢å¤–å…ƒæ•°æ®ï¼‰
    
    Args:
        response_id: å“åº”ID
        query: æŸ¥è¯¢å†…å®¹
        all_content: æ‰€æœ‰æ•°æ®å—å†…å®¹åˆ—è¡¨
        chunk_count: æ•°æ®å—æ•°é‡
        processing_time: å¤„ç†æ—¶é—´
        project_root: é¡¹ç›®æ ¹ç›®å½•
        additional_metadata: é¢å¤–çš„å…ƒæ•°æ®å­—å…¸
        filename_prefix: æ–‡ä»¶åå‰ç¼€ï¼Œé»˜è®¤ä¸º"dify"
        
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¿å­˜å¤±è´¥åˆ™è¿”å›None
    """
    try:
        # ç”Ÿæˆæ–‡ä»¶åï¼šdify_å¹´æœˆæ—¥æ—¶åˆ†ç§’
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename_prefix}_{timestamp}.txt"
        
        # ç¡®ä¿logsç›®å½•å­˜åœ¨
        logs_dir = os.path.join(project_root, "logs")
        os.makedirs(logs_dir, exist_ok=True)
        
        # æ–‡ä»¶å®Œæ•´è·¯å¾„
        file_path = os.path.join(logs_dir, filename)
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            "response_id": response_id,
            "query": query,
            "timestamp": timestamp,
            "chunk_count": chunk_count,
            "processing_time": processing_time,
            "content": all_content
        }
        
        # å¦‚æœæœ‰é¢å¤–å…ƒæ•°æ®ï¼Œæ·»åŠ åˆ°ä¿å­˜æ•°æ®ä¸­
        if additional_metadata:
            save_data.update(additional_metadata)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# Difyå“åº”æ•°æ® - {timestamp}\n")
                f.write(f"# å“åº”ID: {response_id}\n")
                f.write(f"# æŸ¥è¯¢å†…å®¹: {json.dumps(query, ensure_ascii=False, indent=2)}\n")
                f.write(f"# æ•°æ®å—æ•°é‡: {chunk_count}\n")
                f.write(f"# å¤„ç†æ—¶é—´: {save_data['processing_time']:.2f}ç§’\n")
                f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                
                # å†™å…¥é¢å¤–å…ƒæ•°æ®
                if additional_metadata:
                    f.write(f"# é¢å¤–å…ƒæ•°æ®: {json.dumps(additional_metadata, ensure_ascii=False, indent=2)}\n")
                
                f.write("=" * 50 + "\n\n")
                
                # å†™å…¥æ‰€æœ‰æ•°æ®å—å†…å®¹
                for i, content in enumerate(all_content, 1):
                    f.write(f"## æ•°æ®å— {i}\n")
                    f.write(content)
                    f.write("\n\n")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸåˆ›å»º
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                logger.info(f"ğŸ’¾ Difyå“åº”æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {file_path} (å¤§å°: {file_size} å­—èŠ‚)")
                print(f"ğŸ’¾ Difyå“åº”æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {file_path}")
                print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {os.path.abspath(file_path)}")
                print(f"ğŸ“Š æ•°æ®å—æ•°é‡: {chunk_count}")
                print(f"â±ï¸ å¤„ç†æ—¶é—´: {save_data['processing_time']:.2f}ç§’")
                print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                return file_path
            else:
                logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                print(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
                
        except IOError as io_error:
            error_msg = f"å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {str(io_error)}"
            logger.error(f"âŒ {error_msg}")
            print(f"âŒ {error_msg}")
            return None
        except Exception as write_error:
            error_msg = f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(write_error)}"
            logger.error(f"âŒ {error_msg}")
            print(f"âŒ {error_msg}")
            return None
            
    except Exception as save_error:
        error_msg = f"ä¿å­˜Difyå“åº”æ•°æ®åˆ°æ–‡ä»¶æ—¶å‡ºé”™: {str(save_error)}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return None


class DifyStreamingFileWriter:
    """
    è¾¹æµè¾¹å†™çš„æ–‡ä»¶ä¿å­˜å™¨ï¼šåœ¨åå°çº¿ç¨‹ä¸­é¡ºåºå†™å…¥ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯/SSEã€‚
    ä½¿ç”¨æ–¹æ³•ï¼š
      writer = DifyStreamingFileWriter(response_id, query, project_root, filename_prefix)
      writer.start()
      writer.write(line)
      ...
      writer.set_final_stats(chunk_count, processing_time)
      writer.close()  # éé˜»å¡ï¼Œåå°çº¿ç¨‹å®Œæˆæ”¶å°¾
    """

    def __init__(
        self,
        response_id: str,
        query: Any,
        project_root: str,
        filename_prefix: str = "dify",
        additional_metadata: Optional[Dict[str, Any]] = None,
    ) -> None:
        self.response_id = response_id
        self.query = query
        self.project_root = project_root
        self.filename_prefix = filename_prefix
        self.additional_metadata = additional_metadata or {}

        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        logs_dir = os.path.join(self.project_root, "logs")
        os.makedirs(logs_dir, exist_ok=True)
        self.file_path = os.path.join(logs_dir, f"{self.filename_prefix}_{self.timestamp}.txt")

        self._queue: "queue.Queue[Optional[str]]" = queue.Queue()
        self._thread: Optional[threading.Thread] = None
        self._chunk_index: int = 0
        self._final_stats: Dict[str, Any] = {}

    def start(self) -> None:
        if self._thread and self._thread.is_alive():
            return

        def _worker() -> None:
            try:
                with open(self.file_path, "w", encoding="utf-8") as f:
                    # header
                    f.write(f"# Difyå“åº”æ•°æ® - {self.timestamp}\n")
                    f.write(f"# å“åº”ID: {self.response_id}\n")
                    f.write(f"# æŸ¥è¯¢å†…å®¹: {json.dumps(self.query, ensure_ascii=False, indent=2)}\n")
                    if self.additional_metadata:
                        f.write(f"# é¢å¤–å…ƒæ•°æ®: {json.dumps(self.additional_metadata, ensure_ascii=False, indent=2)}\n")
                    f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("=" * 50 + "\n\n")

                    # stream body
                    while True:
                        item = self._queue.get()
                        if item is None:
                            break
                        self._chunk_index += 1
                        f.write(f"## æ•°æ®å— {self._chunk_index}\n")
                        f.write(item)
                        if not item.endswith("\n"):
                            f.write("\n")
                        f.write("\n")
                        f.flush()

                    # footer with stats
                    if self._final_stats:
                        f.write("=" * 50 + "\n")
                        if "chunk_count" in self._final_stats:
                            f.write(f"# æ•°æ®å—æ•°é‡: {self._final_stats['chunk_count']}\n")
                        if "processing_time" in self._final_stats:
                            f.write(f"# å¤„ç†æ—¶é—´: {self._final_stats['processing_time']:.2f}ç§’\n")
                        f.flush()

                if os.path.exists(self.file_path):
                    try:
                        file_size = os.path.getsize(self.file_path)
                        logger.info(
                            f"ğŸ’¾ Difyå“åº”æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {self.file_path} (å¤§å°: {file_size} å­—èŠ‚)"
                        )
                        print(f"ğŸ’¾ Difyå“åº”æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {self.file_path}")
                    except Exception:
                        pass
                else:
                    logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")
            except Exception as e:
                logger.error(f"âŒ æµå¼ä¿å­˜çº¿ç¨‹å¼‚å¸¸: {e}")

        self._thread = threading.Thread(target=_worker, daemon=True)
        self._thread.start()
        # å¯åŠ¨æ—¶å°±æ‰“å°è®¡åˆ’å†™å…¥çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾¿äºå®šä½
        try:
            print(f"ğŸ—‚ï¸ è®¡åˆ’å†™å…¥Difyæµå¼æ–‡ä»¶: {os.path.abspath(self.file_path)}")
            logger.info(f"ğŸ—‚ï¸ è®¡åˆ’å†™å…¥Difyæµå¼æ–‡ä»¶: {os.path.abspath(self.file_path)}")
        except Exception:
            pass

    def write(self, line: str) -> None:
        try:
            self._queue.put_nowait(line)
        except Exception:
            pass

    def set_final_stats(self, chunk_count: int = None, processing_time: float = None) -> None:
        if chunk_count is not None:
            self._final_stats["chunk_count"] = chunk_count
        if processing_time is not None:
            self._final_stats["processing_time"] = processing_time

    def close(self) -> None:
        # éé˜»å¡å…³é—­ï¼Œåå°çº¿ç¨‹å®Œæˆæ”¶å°¾
        try:
            self._queue.put_nowait(None)
        except Exception:
            pass


def start_dify_stream_saver(
    response_id: str,
    query: Any,
    project_root: str,
    filename_prefix: str = "dify",
    additional_metadata: Optional[Dict[str, Any]] = None,
    enable_stream_save: Optional[bool] = None,
    use_env: bool = False,
) -> Tuple[Optional[DifyStreamingFileWriter], bool]:
    """
    æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦å¯åŠ¨æµå¼ä¿å­˜å™¨ã€‚
    è¿”å› (stream_saver, enable_stream_save)ã€‚æœªå¯ç”¨æ—¶è¿”å› (None, False)ã€‚
    - enable_stream_save: æ˜¾å¼å¼€å…³ï¼›
    - use_env: è‹¥ä¸º True ä¸” enable_stream_save ä¸º Noneï¼Œåˆ™è¯»å–ç¯å¢ƒå˜é‡ DIFY_ENABLE_STREAM_SAVEï¼›
      å¦åˆ™é»˜è®¤ Falseï¼ˆç¬¦åˆâ€œå¤–éƒ¨é»˜è®¤ä¸ä¼ å°±æ˜¯ falseâ€ï¼‰ã€‚
    """
    if enable_stream_save is None:
        if use_env:
            enable_stream_save = os.getenv("DIFY_ENABLE_STREAM_SAVE", "0").lower() in ["1", "true", "yes"]
        else:
            enable_stream_save = False

    if not enable_stream_save:
        return None, False

    writer = DifyStreamingFileWriter(
        response_id=response_id,
        query=query,
        project_root=project_root,
        filename_prefix=filename_prefix,
        additional_metadata=additional_metadata,
    )
    writer.start()
    return writer, True
